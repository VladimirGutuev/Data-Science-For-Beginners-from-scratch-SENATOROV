{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ff795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Working with input and output stream, with text files and json.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19502573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from sys import stdin\n",
    "from typing import Iterator, TypedDict\n",
    "\n",
    "\n",
    "def task_1() -> None:\n",
    "    \"\"\"Sum all numbers in input stream.\"\"\"\n",
    "    summary: int = 0\n",
    "    for line in stdin:\n",
    "        line = line.strip(\"\\n\")\n",
    "        summary += sum(map(int, line.split()))\n",
    "    print(summary)\n",
    "\n",
    "\n",
    "task_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2() -> None:\n",
    "    \"\"\"Print rounded change of average height in class.\"\"\"\n",
    "    previous_heights: list[int] = []\n",
    "    current_heights: list[int] = []\n",
    "\n",
    "    for line in stdin:\n",
    "        parts: list[str] = line.split()\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        _, prev_str, curr_str = parts\n",
    "        previous_heights.append(int(prev_str))\n",
    "        current_heights.append(int(curr_str))\n",
    "\n",
    "    if not previous_heights:\n",
    "        print(0)\n",
    "        return\n",
    "\n",
    "    previous_avg: float = sum(previous_heights) / len(previous_heights)\n",
    "    current_avg: float = sum(current_heights) / len(current_heights)\n",
    "    change_avg: float = current_avg - previous_avg\n",
    "\n",
    "    print(round(change_avg))\n",
    "\n",
    "\n",
    "task_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_3() -> None:\n",
    "    \"\"\"Print program lines without comments.\"\"\"\n",
    "    for source_line in stdin:\n",
    "        line: str = source_line.rstrip(\"\\n\")\n",
    "        if line.lstrip().startswith(\"#\"):\n",
    "            continue\n",
    "\n",
    "        in_single: bool = False\n",
    "        in_double: bool = False\n",
    "        escaped: bool = False\n",
    "        result_chars: list[str] = []\n",
    "\n",
    "        for ch in line:\n",
    "            if ch == \"\\\\\" and not escaped:\n",
    "                result_chars.append(ch)\n",
    "                escaped = True\n",
    "                continue\n",
    "\n",
    "            if not escaped and ch == \"'\" and not in_double:\n",
    "                in_single = not in_single\n",
    "            elif not escaped and ch == '\"' and not in_single:\n",
    "                in_double = not in_double\n",
    "            elif ch == \"#\" and not in_single and not in_double:\n",
    "                break\n",
    "\n",
    "            result_chars.append(ch)\n",
    "            escaped = False\n",
    "\n",
    "        cleaned: str = \"\".join(result_chars)\n",
    "        print(cleaned)\n",
    "\n",
    "\n",
    "task_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52384291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_4() -> None:\n",
    "    \"\"\"Print page titles containing the query (case-insensitive).\"\"\"\n",
    "    lines: list[str] = [ln.rstrip(\"\\n\") for ln in stdin]\n",
    "    if not lines:\n",
    "        return\n",
    "\n",
    "    query: str = lines[-1]\n",
    "    titles: list[str] = lines[:-1]\n",
    "    normalized_query: str = query.casefold()\n",
    "\n",
    "    for title in titles:\n",
    "        if normalized_query in title.casefold():\n",
    "            print(title)\n",
    "\n",
    "\n",
    "task_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_5() -> None:\n",
    "    \"\"\"Print unique palindromic words sorted alphabetically.\"\"\"\n",
    "    result: set[str] = set()\n",
    "\n",
    "    for line in stdin:\n",
    "        for word in line.split():\n",
    "            normalized: str = word.casefold()\n",
    "            if normalized == normalized[::-1]:\n",
    "                result.add(word)\n",
    "\n",
    "    for word in sorted(result):\n",
    "        print(word)\n",
    "\n",
    "\n",
    "task_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_6() -> None:\n",
    "    \"\"\"Transliterate cyrillic.txt to transliteration.txt per rules.\"\"\"\n",
    "    lower_map: dict[str, str] = {\n",
    "        \"а\": \"a\",\n",
    "        \"б\": \"b\",\n",
    "        \"в\": \"v\",\n",
    "        \"г\": \"g\",\n",
    "        \"д\": \"d\",\n",
    "        \"е\": \"e\",\n",
    "        \"ё\": \"e\",\n",
    "        \"ж\": \"zh\",\n",
    "        \"з\": \"z\",\n",
    "        \"и\": \"i\",\n",
    "        \"й\": \"i\",\n",
    "        \"к\": \"k\",\n",
    "        \"л\": \"l\",\n",
    "        \"м\": \"m\",\n",
    "        \"н\": \"n\",\n",
    "        \"о\": \"o\",\n",
    "        \"п\": \"p\",\n",
    "        \"р\": \"r\",\n",
    "        \"с\": \"s\",\n",
    "        \"т\": \"t\",\n",
    "        \"у\": \"u\",\n",
    "        \"ф\": \"f\",\n",
    "        \"х\": \"kh\",\n",
    "        \"ц\": \"tc\",\n",
    "        \"ч\": \"ch\",\n",
    "        \"ш\": \"sh\",\n",
    "        \"щ\": \"shch\",\n",
    "        \"ы\": \"y\",\n",
    "        \"э\": \"e\",\n",
    "        \"ю\": \"iu\",\n",
    "        \"я\": \"ia\",\n",
    "        \"ъ\": \"\",\n",
    "        \"ь\": \"\",\n",
    "    }\n",
    "    upper_map: dict[str, str] = {\n",
    "        \"А\": \"A\",\n",
    "        \"Б\": \"B\",\n",
    "        \"В\": \"V\",\n",
    "        \"Г\": \"G\",\n",
    "        \"Д\": \"D\",\n",
    "        \"Е\": \"E\",\n",
    "        \"Ё\": \"E\",\n",
    "        \"Ж\": \"Zh\",\n",
    "        \"З\": \"Z\",\n",
    "        \"И\": \"I\",\n",
    "        \"Й\": \"I\",\n",
    "        \"К\": \"K\",\n",
    "        \"Л\": \"L\",\n",
    "        \"М\": \"M\",\n",
    "        \"Н\": \"N\",\n",
    "        \"О\": \"O\",\n",
    "        \"П\": \"P\",\n",
    "        \"Р\": \"R\",\n",
    "        \"С\": \"S\",\n",
    "        \"Т\": \"T\",\n",
    "        \"У\": \"U\",\n",
    "        \"Ф\": \"F\",\n",
    "        \"Х\": \"Kh\",\n",
    "        \"Ц\": \"Tc\",\n",
    "        \"Ч\": \"Ch\",\n",
    "        \"Ш\": \"Sh\",\n",
    "        \"Щ\": \"Shch\",\n",
    "        \"Ы\": \"Y\",\n",
    "        \"Э\": \"E\",\n",
    "        \"Ю\": \"Iu\",\n",
    "        \"Я\": \"Ia\",\n",
    "        \"Ъ\": \"\",\n",
    "        \"Ь\": \"\",\n",
    "    }\n",
    "\n",
    "    with open(\"cyrillic.txt\", encoding=\"utf-8\") as src:\n",
    "        text: str = src.read()\n",
    "\n",
    "    out_parts: list[str] = []\n",
    "    for ch in text:\n",
    "        if ch in lower_map:\n",
    "            out_parts.append(lower_map[ch])\n",
    "        elif ch in upper_map:\n",
    "            out_parts.append(upper_map[ch])\n",
    "        else:\n",
    "            out_parts.append(ch)\n",
    "\n",
    "    with open(\"transliteration.txt\", \"w\", encoding=\"utf-8\") as dst:\n",
    "        dst.write(\"\".join(out_parts))\n",
    "\n",
    "\n",
    "task_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_7() -> None:\n",
    "    \"\"\"Print basic stats for numbers in a file.\"\"\"\n",
    "    filename: str = input()\n",
    "\n",
    "    with open(filename, encoding=\"utf-8\") as src:\n",
    "        numbers: list[int] = [int(token) for token in src.read().split()]\n",
    "\n",
    "    count_all: int = len(numbers)\n",
    "    count_positive: int = sum(1 for value in numbers if value > 0)\n",
    "    min_value: int = min(numbers)\n",
    "    max_value: int = max(numbers)\n",
    "    total_sum: int = sum(numbers)\n",
    "    average: float = total_sum / count_all\n",
    "\n",
    "    print(count_all)\n",
    "    print(count_positive)\n",
    "    print(min_value)\n",
    "    print(max_value)\n",
    "    print(total_sum)\n",
    "    print(f\"{average:.2f}\")\n",
    "\n",
    "\n",
    "task_7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e346c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_8() -> None:\n",
    "    \"\"\"Write unique words from two files into third file, sorted.\"\"\"\n",
    "    first_filename: str = input()\n",
    "    second_filename: str = input()\n",
    "    output_filename: str = input()\n",
    "\n",
    "    with open(first_filename, encoding=\"utf-8\") as first_file:\n",
    "        words_first: set[str] = set(first_file.read().split())\n",
    "\n",
    "    with open(second_filename, encoding=\"utf-8\") as second_file:\n",
    "        words_second: set[str] = set(second_file.read().split())\n",
    "\n",
    "    only_in_one: list[str] = sorted(words_first ^ words_second)\n",
    "\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        out_file.write(\"\\n\".join(only_in_one))\n",
    "\n",
    "\n",
    "task_8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_9() -> None:\n",
    "    \"\"\"Clean text using only str.replace (tabs, spaces, newlines).\"\"\"\n",
    "    source_name: str = input()\n",
    "    output_name: str = input()\n",
    "\n",
    "    with open(source_name, encoding=\"utf-8\") as src:\n",
    "        text: str = src.read()\n",
    "\n",
    "    # удаляем табы\n",
    "    text = text.replace(\"\\t\", \"\")\n",
    "\n",
    "    # схлопываем повторяющиеся пробелы\n",
    "    while \"  \" in text:\n",
    "        text = text.replace(\"  \", \" \")\n",
    "\n",
    "    # убираем пробелы в начале/конце каждой строки\n",
    "    while \"\\n \" in text or \" \\n\" in text or text.startswith(\" \") or text.endswith(\" \"):\n",
    "        text = text.replace(\"\\n \", \"\\n\")\n",
    "        text = text.replace(\" \\n\", \"\\n\")\n",
    "        if text.startswith(\" \"):\n",
    "            text = text[1:]\n",
    "        if text.endswith(\" \"):\n",
    "            text = text[:-1]\n",
    "\n",
    "    # схлопываем повторяющиеся переводы строки\n",
    "    while \"\\n\\n\" in text:\n",
    "        text = text.replace(\"\\n\\n\", \"\\n\")\n",
    "\n",
    "    with open(output_name, \"w\", encoding=\"utf-8\") as dst:\n",
    "        dst.write(text)\n",
    "\n",
    "\n",
    "task_9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2783fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_10() -> None:\n",
    "    \"\"\"Print the last N lines of a file (tail).\"\"\"\n",
    "    filename: str = input()\n",
    "    lines_to_show: int = int(input())\n",
    "\n",
    "    block_size: int = 4096\n",
    "    chunks: list[bytes] = []\n",
    "    newline_count: int = 0\n",
    "\n",
    "    with open(filename, \"rb\") as fh:\n",
    "        fh.seek(0, 2)  # в конец файла\n",
    "        pos: int = fh.tell()\n",
    "\n",
    "        while pos > 0 and newline_count <= lines_to_show:\n",
    "            read_size: int = block_size if pos >= block_size else pos\n",
    "            pos -= read_size\n",
    "            fh.seek(pos)\n",
    "            chunk: bytes = fh.read(read_size)\n",
    "            chunks.append(chunk)\n",
    "            newline_count += chunk.count(b\"\\n\")\n",
    "\n",
    "    data: bytes = b\"\".join(reversed(chunks)).rstrip(b\"\\n\")\n",
    "    if not data or lines_to_show <= 0:\n",
    "        return\n",
    "\n",
    "    lines: list[bytes] = data.split(b\"\\n\")\n",
    "    tail_lines: list[bytes] = lines[-lines_to_show:]\n",
    "\n",
    "    for raw in tail_lines:\n",
    "        print(raw.decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "task_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fd0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_11() -> None:\n",
    "    \"\"\"Save basic stats of numbers from a file to JSON.\"\"\"\n",
    "    source_name: str = input()\n",
    "    output_name: str = input()\n",
    "\n",
    "    with open(source_name, encoding=\"utf-8\") as src:\n",
    "        numbers: list[int] = [int(tok) for tok in src.read().split()]\n",
    "\n",
    "    count_all: int = len(numbers)\n",
    "    positive_count: int = sum(1 for v in numbers if v > 0)\n",
    "    min_value: int = min(numbers)\n",
    "    max_value: int = max(numbers)\n",
    "    total_sum: int = sum(numbers)\n",
    "    average: float = round(total_sum / count_all, 2)\n",
    "\n",
    "    stats: dict[str, int | float] = {\n",
    "        \"count\": count_all,\n",
    "        \"positive_count\": positive_count,\n",
    "        \"min\": min_value,\n",
    "        \"max\": max_value,\n",
    "        \"sum\": total_sum,\n",
    "        \"average\": average,\n",
    "    }\n",
    "\n",
    "    with open(output_name, \"w\", encoding=\"utf-8\") as out:\n",
    "        json.dump(stats, out, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "task_11()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_12() -> None:\n",
    "    \"\"\"Split numbers by digit parity domination into three files.\"\"\"\n",
    "    source_name: str = input()\n",
    "    out_names: list[str] = [input(), input(), input()]\n",
    "    out_lines: list[list[str]] = [[], [], []]\n",
    "\n",
    "    with open(source_name, encoding=\"utf-8\") as src_file:\n",
    "        for line in src_file:\n",
    "            parts: list[str] = line.split()\n",
    "            per_bucket: list[list[str]] = [[], [], []]\n",
    "\n",
    "            for token in parts:\n",
    "                digits: str = token.lstrip(\"+-\")\n",
    "                even_count: int = sum(ch in \"02468\" for ch in digits)\n",
    "                twice_even: int = even_count * 2\n",
    "                if twice_even > len(digits):\n",
    "                    bucket_index: int = 0\n",
    "                elif twice_even < len(digits):\n",
    "                    bucket_index = 1\n",
    "                else:\n",
    "                    bucket_index = 2\n",
    "                per_bucket[bucket_index].append(token)\n",
    "\n",
    "            for bucket_index in range(3):\n",
    "                out_lines[bucket_index].append(\" \".join(per_bucket[bucket_index]))\n",
    "\n",
    "    for bucket_index, name in enumerate(out_names):\n",
    "        with open(name, \"w\", encoding=\"utf-8\") as dst:\n",
    "            dst.write(\"\\n\".join(out_lines[bucket_index]) + \"\\n\")\n",
    "\n",
    "\n",
    "task_12()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ce139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_13() -> None:\n",
    "    \"\"\"Update a JSON file with key == value lines from stdin.\"\"\"\n",
    "    filename: str = input()\n",
    "\n",
    "    with open(filename, encoding=\"utf-8\") as src:\n",
    "        raw: dict[str, object] = json.load(src)\n",
    "    data: dict[str, str] = {k: str(v) for k, v in raw.items()}\n",
    "\n",
    "    for raw_line in stdin:\n",
    "        if \"==\" not in raw_line:\n",
    "            continue\n",
    "        key_part, value_part = raw_line.split(\"==\", 1)\n",
    "        key: str = key_part.strip()\n",
    "        value: str = value_part.strip()\n",
    "        if key:\n",
    "            data[key] = value\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as dst:\n",
    "        json.dump(data, dst, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "task_13()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_14() -> None:\n",
    "    \"\"\"Merge users and updates into name-keyed JSON with max values.\"\"\"\n",
    "    users_filename: str = input()\n",
    "    updates_filename: str = input()\n",
    "\n",
    "    users_map: dict[str, dict[str, str]] = {}\n",
    "\n",
    "    # Загружаем исходных пользователей и сразу раскладываем в словарь\n",
    "    with open(users_filename, encoding=\"utf-8\") as src:\n",
    "        for rec in json.load(src):\n",
    "            user_name: str = str(rec.get(\"name\", \"\"))\n",
    "            if not user_name:\n",
    "                continue\n",
    "            users_map[user_name] = {\n",
    "                key: str(val) for key, val in rec.items() if key != \"name\"\n",
    "            }\n",
    "\n",
    "    # Применяем обновления: при конфликте берём лексикографически большее\n",
    "    with open(updates_filename, encoding=\"utf-8\") as src:\n",
    "        for rec in json.load(src):\n",
    "            upd_name: str = str(rec.get(\"name\", \"\"))\n",
    "            if not upd_name:\n",
    "                continue\n",
    "            upd_fields: dict[str, str] = {\n",
    "                key: str(val) for key, val in rec.items() if key != \"name\"\n",
    "            }\n",
    "            current: dict[str, str] = users_map.get(upd_name, {})\n",
    "            for field, new_val in upd_fields.items():\n",
    "                current[field] = (\n",
    "                    new_val if field not in current else max(current[field], new_val)\n",
    "                )\n",
    "            users_map[upd_name] = current\n",
    "\n",
    "    with open(users_filename, \"w\", encoding=\"utf-8\") as dst:\n",
    "        json.dump(users_map, dst, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "task_14()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = TypedDict(\"Test\", {\"input\": str, \"pattern\": str})\n",
    "Group = TypedDict(\"Group\", {\"points\": int, \"tests\": list[Test]})\n",
    "\n",
    "\n",
    "def task_15() -> None:\n",
    "    \"\"\"Compute score from stdin answers using scoring.json spec.\"\"\"\n",
    "    with open(\"scoring.json\", encoding=\"utf-8\") as src:\n",
    "        groups: list[Group] = json.load(src)\n",
    "\n",
    "    answers: Iterator[str] = (line.strip() for line in stdin)\n",
    "    total_points: int = 0\n",
    "\n",
    "    for group in groups:\n",
    "        points: int = int(group[\"points\"])\n",
    "        tests: list[Test] = group[\"tests\"]\n",
    "        per_test: int = points // len(tests)\n",
    "        passed: int = 0\n",
    "\n",
    "        for test in tests:\n",
    "            expected: str = test[\"pattern\"]\n",
    "            actual: str = next(answers, \"\")\n",
    "            if actual == expected:\n",
    "                passed += 1\n",
    "\n",
    "        total_points += per_test * passed\n",
    "\n",
    "    print(total_points)\n",
    "\n",
    "\n",
    "task_15()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7929da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text: str) -> str:\n",
    "    \"\"\"Lowercase and collapse all whitespace into single spaces.\"\"\"\n",
    "    return \" \".join(text.casefold().split())\n",
    "\n",
    "\n",
    "def task_16() -> None:\n",
    "    \"\"\"Print files where query occurs ignoring case and whitespace.\"\"\"\n",
    "    query_raw: str = input()\n",
    "    filenames: list[str] = [name.rstrip(\"\\n\") for name in stdin]\n",
    "\n",
    "    query_norm: str = normalize(query_raw)\n",
    "    matched: list[str] = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        with open(filename, encoding=\"utf-8\") as src:\n",
    "            content_norm: str = normalize(src.read())\n",
    "        if query_norm in content_norm:\n",
    "            matched.append(filename)\n",
    "\n",
    "    if matched:\n",
    "        print(\"\\n\".join(matched))\n",
    "    else:\n",
    "        print(\"404. Not Found\")\n",
    "\n",
    "\n",
    "task_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_17() -> None:\n",
    "    \"\"\"Reveal message by taking the low byte of each character.\"\"\"\n",
    "    with open(\"secret.txt\", encoding=\"utf-8\") as src:\n",
    "        secret_text: str = src.read()\n",
    "\n",
    "    decoded_chars: list[str] = []\n",
    "    for symbol in secret_text:\n",
    "        code_point: int = ord(symbol)\n",
    "        new_code: int = code_point if code_point < 128 else (code_point & 0xFF)\n",
    "        decoded_chars.append(chr(new_code))\n",
    "\n",
    "    print(\"\".join(decoded_chars))\n",
    "\n",
    "\n",
    "task_17()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db88bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_18() -> None:\n",
    "    \"\"\"Print file size in standard units with ceiling rounding.\"\"\"\n",
    "    filename: str = input()\n",
    "    size_bytes: int = os.path.getsize(filename)\n",
    "\n",
    "    units: list[tuple[str, int]] = [\n",
    "        (\"Б\", 1),\n",
    "        (\"КБ\", 1024),\n",
    "        (\"МБ\", 1024**2),\n",
    "        (\"ГБ\", 1024**3),\n",
    "    ]\n",
    "\n",
    "    if size_bytes == 0:\n",
    "        print(\"0Б\")\n",
    "        return\n",
    "\n",
    "    unit_name: str = \"Б\"\n",
    "    divisor: int = 1\n",
    "    for name, factor in units:\n",
    "        if factor <= size_bytes:\n",
    "            unit_name, divisor = name, factor\n",
    "\n",
    "    value: int = math.ceil(size_bytes / divisor)\n",
    "    print(f\"{value}{unit_name}\")\n",
    "\n",
    "\n",
    "task_18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0242ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_19() -> None:\n",
    "    \"\"\"Encrypt public.txt using Caesar shift for Latin letters only.\"\"\"\n",
    "    shift_value: int = int(input())\n",
    "    offset: int = shift_value % 26\n",
    "\n",
    "    def shift_letter(symbol: str, offset_val: int) -> str:\n",
    "        \"\"\"Shift one Latin letter by offset; keep others unchanged.\"\"\"\n",
    "        if \"a\" <= symbol <= \"z\":\n",
    "            base: int = ord(\"a\")\n",
    "            pos: int = ord(symbol) - base\n",
    "            return chr(base + (pos + offset_val) % 26)\n",
    "        if \"A\" <= symbol <= \"Z\":\n",
    "            base = ord(\"A\")\n",
    "            pos = ord(symbol) - base\n",
    "            return chr(base + (pos + offset_val) % 26)\n",
    "        return symbol\n",
    "\n",
    "    with open(\"public.txt\", encoding=\"utf-8\") as src:\n",
    "        plain_text: str = src.read()\n",
    "\n",
    "    cipher_text: str = \"\".join(shift_letter(ch, offset) for ch in plain_text)\n",
    "\n",
    "    with open(\"private.txt\", \"w\", encoding=\"utf-8\") as dst:\n",
    "        dst.write(cipher_text)\n",
    "\n",
    "\n",
    "task_19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e68d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_20() -> None:\n",
    "    \"\"\"Sum 2-byte big-endian numbers from numbers.num with 16-bit wrap.\"\"\"\n",
    "    with open(\"numbers.num\", \"rb\") as src:\n",
    "        payload: bytes = src.read()\n",
    "\n",
    "    usable_len: int = len(payload) - (len(payload) % 2)\n",
    "    total_sum: int = sum(\n",
    "        int.from_bytes(payload[i : i + 2], \"big\", signed=False)\n",
    "        for i in range(0, usable_len, 2)\n",
    "    )\n",
    "\n",
    "    print(total_sum % (1 << 16))\n",
    "\n",
    "\n",
    "task_20()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
