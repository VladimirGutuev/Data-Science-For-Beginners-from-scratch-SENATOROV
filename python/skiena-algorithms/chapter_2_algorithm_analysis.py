"""This module includes a summary of Chapter 2 of Skiena's book (pp.

55-65).
"""

# # Анализ алгоритмов
# ## 2.1 Модель вычислений RAM
# Разработка машинно-независимых алгоритмов основывается на гипотетическом
# компьютере, называемом машиной с произвольным доступом к памяти. Согласно
# этой модели наш компьютер работает таким образом:
# - для исполнения любой простой операции ( +, *, -, =, if, call) требуется
# ровно один
# временной шаг;
# - циклы и подпрограммы не считаются простыми операциями, а состоят из
# нескольких простых операций;
# - каждое обращение к памяти занимает один временной шаг. Кроме этого, наш
# компьютер обладает неограниченным объемом оперативной памяти. Кэш и диск в
# модели RAM не применяются.
#
# ### 2.1.1 Анализ сложности наилучшего, наихудшего и среднего случая
# - Сложность алгоритма в наихудшем случае - это функция, определяемая
# максимальным количеством шагов, требуемых для обработки любого входного
# экземпляра размером п. Этот случай отображается кривой, проходящей через
# самую высшую точку каждого столбца;
# - Сложность алгоритма в наилучшем случае - это функция, определяемая
# минимальным количеством шагов, требуемых для обработки любого входного
# экземпляра размером п. Этот случай отображается кривой, проходящей через
# самую низшую точку каждого столбца;
# - Сложность алгоритма в среднем случае, или его ожидаемое время, - это
# функция, определяемая средним количеством шагов, требуемых для обработки
# всех экземпляров размером n.
#
# ![image.png](attachment:image.png)
#
# Анализ времени исполнения среднего случая очень важный для рандомизированных
# алгоритмов, т. е. алгоритмов, использующих случайные числа для принятия
# решений.
#
# ## 2.2 Асимптотические ("Big Oh") обозначения
# Формальные определения, связанные с асимптотическими обозначениями, выглядят
# таким образом:
# - f{n) = О(g(n)) означает, что функция f{n) ограничена сверху функцией с· g
# (n). Иными словами, существует такая константа с, при которой f{n) <= с· g(n)
# для каждого достаточно большого значения n (т. е. для всех n >= n0 для
# некоторой константы n0). Этот случай показан на рис. 2.3, а;
# - f{n) = Q(g(n)) означает, что функция f{п) ограничена снизу функцией с · g
# (n). Иными словами, существует такая константа с, для которой f{n) >= с· g(n)
# для всех n >= n0• Этот случай показан на рис. 2.3, 6;
# - f(n) = Е>(g(n)) означает, что функция f(n) ограничена сверху функцией с1 •
# g(n), а снизу функцией с2 • g(n) для всех n ~ п0• Иными словами, существуют
# константы с1 и с2, для которых f(n) :5 с1 • g(n) и f(n) ~ с2 • g(n) для всех
# n >= n0.
#
# ## 2.3 Скорость роста и отношения доминирования
#
# ![image-2.png](attachment:image-2.png)
#
# ### 2.3.1 Отношения доминирования
# п! » 2**n » n**3 » n**2 » nlogn » n » logn » 1
#
# ## 2.4 Работа с асимптотическими обозначениями
# ### 2.4.1 Сложение функций
# Сумма двух функций определяется доминантной функцией, а именно: f(n) + g(n)
# -> 0(max(f{n), g(n))).
# Это обстоятельство очень полезно при упрощении выражений. Например, из него
# следует, что n3 + n2 + n + 1 = О(n3).
#
# ### 2.4.2 Умножение функций
# Умножение можно представлять как повторяющееся сложение. Таким образом:
#
# ![image-3.png](attachment:image-3.png)
#
# С другой стороны, когда обе функции произведения возрастают, то обе являются
# важными. Функция О(n! logn) доминирует над функцией n! настолько же,
# насколько и функция log n доминирует над константой 1. В общем,
#
# ![image-4.png](attachment:image-4.png)
